{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715ee3f-6871-4d57-b0ef-3f5bcb5a656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When training this model, Python version 3.8.10 has been used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ef3fb-bf94-4c09-857b-7d8e5271a7f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:58:11.688289600Z",
     "start_time": "2024-06-16T12:57:44.358522200Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the libraries: \n",
    "# The versions that were used for this model are annotated per library.\n",
    "\n",
    "import os\n",
    "import numpy as np              # Version used: 1.23.1\n",
    "import glob\n",
    "import monai                    # Version used: 1.3.0\n",
    "from monai.transforms import * \n",
    "import SimpleITK as sitk        # Version used: 2.3.1\n",
    "import torch                    # Version used: 1.13.1+cu116\n",
    "from tqdm import tqdm\n",
    "import wandb                    # Version used: 0.17.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2831b4-73de-4b92-867b-99ddd1302b8d",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a710f-fec7-49fe-a43f-cfddd2609776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:58:11.726184200Z",
     "start_time": "2024-06-16T12:58:11.709231600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A function 'build_dicts' is made to obtain the filenames from the given dataset.\n",
    "def build_dicts(data_path='database', mode=\"training\"):\n",
    "\n",
    "    # Check if the mode is training or testing:\n",
    "    if mode not in [\"training\", \"testing\"]:\n",
    "        raise ValueError(f\"Please choose a mode in ['training', 'testing']. Current mode is {mode}.\")\n",
    "\n",
    "    # Finding the .nii.gz files in the dataset matching the folder and directory names with the variability of patientnumbers and frames. \n",
    "    paths_xray = glob.glob(os.path.join(data_path, mode, 'patient*', 'patient*_frame[0-9][0-9].nii.gz'))\n",
    "\n",
    "    dicts = []\n",
    "    # Iterate over each file path and extract the ground truth files from the scan file. \n",
    "    for scan_file in paths_xray:\n",
    "        extension_index = scan_file.index(\".\")\n",
    "        gt_file = scan_file[:extension_index] + \"_gt\" + scan_file[extension_index:]\n",
    "\n",
    "        directory = scan_file.split(os.sep)[:-1]\n",
    "        cfg_file = os.path.join(*directory, \"Info.cfg\")\n",
    "\n",
    "        # Open the info.cfg files to extraxt the disease information for completeness.\n",
    "        with open(cfg_file, \"r\") as f:\n",
    "            line = f.readlines()[2]\n",
    "            disease = line.split(\": \")[1]\n",
    "\n",
    "        # Make a dictionary with a scan file path, the ground truth file path, and the disease\n",
    "        if os.path.exists(gt_file):\n",
    "            dicts.append({\"scan_file\": scan_file, \n",
    "                          \"gt_file\": gt_file, \n",
    "                          \"class\": disease})\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9691609-6250-4b0b-9f59-82bc9eb989b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A function 'split_train_val' is made to make a training and a validation set using Numpy.\n",
    "def split_train_val(train_list, ratio):\n",
    "    # Making a random index where 10 indices are chosen that are used for the validation set.\n",
    "        # These 10 indices are obtained by dividing the entire length of the trainlist (which is 200) by two.\n",
    "        # This is divided by two, since the set needs to be splitted on patient level and there are 200 scans (a diastoly scan and a systole) of 100 patients.\n",
    "        # Then a ratio can be defined to choose the size of the validation set.\n",
    "    val_idx = np.random.choice(len(train_list)//2,\n",
    "                               int(len(train_list) * ratio)//2, replace=False)\n",
    "    \n",
    "    train_dicts = []\n",
    "    val_dicts = []\n",
    "    # Iterated over all patients, 10 patients are extracted based on the val_idx that is computed.\n",
    "    for sample in train_list:\n",
    "        patient = int(sample['scan_file'][-17:-15])\n",
    "        \n",
    "        # The validation dictionairy is computed with 10 patients and 20 files.\n",
    "        if patient in val_idx:\n",
    "            val_dicts.append(sample)\n",
    "            \n",
    "        # The training dictionairy is computed with 90 patients and 180 files. \n",
    "        else:\n",
    "            train_dicts.append(sample)\n",
    "            \n",
    "    return train_dicts, val_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab9450-dc86-4101-8139-ac1c47c72c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:58:11.746128600Z",
     "start_time": "2024-06-16T12:58:11.725186800Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A function 'ReadFiles' is made to read out scan files from a specific dictionary using SimpleITK.\n",
    "class ReadFiles(monai.transforms.Transform):\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        # Read out the scan file without the ground truth\n",
    "        image = sitk.ReadImage(sample[\"scan_file\"])\n",
    "\n",
    "        # Read out the scan file with the ground truth\n",
    "        mask = sitk.ReadImage(sample[\"gt_file\"])\n",
    "\n",
    "        # Returning a dictionary contain all the relevant information\n",
    "        return {\"img\": image,                      # Object of the scan file without the segmenation\n",
    "                \"mask\": mask,                      # Object of the mask of the ground truth segmentation\n",
    "                \"img_size\": image.GetSize(),       # Size of each scan file\n",
    "                \"img_spacing\": image.GetSpacing(), # Spacing of the voxels of each scan file\n",
    "                \"class\": sample[\"class\"],          # The disease label of each scan file\n",
    "                \"scan_file\": sample[\"scan_file\"]   # Path to the scan file\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3d065-b30d-4c26-8ac4-050ff4ab53af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:58:11.710228900Z",
     "start_time": "2024-06-16T12:58:11.693275400Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A function 'resample_img' is made to set the spacing of the SITK image\n",
    "def resample_img(itk_image, out_spacing, is_label):\n",
    "    original_spacing = itk_image.GetSpacing()\n",
    "    original_size = itk_image.GetSize()\n",
    "\n",
    "    # Calculate the output size, after the image has been respaced\n",
    "    out_size = [\n",
    "        int(np.round(original_size[0] * (original_spacing[0] / out_spacing[0]))),\n",
    "        int(np.round(original_size[1] * (original_spacing[1] / out_spacing[1]))),\n",
    "        int(np.round(original_size[2] * (original_spacing[2] / out_spacing[2])))]\n",
    "\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetOutputSpacing(out_spacing)\n",
    "    resample.SetSize(out_size)\n",
    "    resample.SetOutputDirection(itk_image.GetDirection())\n",
    "    resample.SetOutputOrigin(itk_image.GetOrigin())\n",
    "\n",
    "    if is_label: \n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor) # Use nearest neighbour for labels\n",
    "    else:\n",
    "        resample.SetInterpolator(sitk.sitkBSpline)\n",
    "\n",
    "    return resample.Execute(itk_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f793a8-e5dc-4404-a455-38fb69b2c338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:58:11.782029300Z",
     "start_time": "2024-06-16T12:58:11.739148600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A function 'EqualizeSpacing' is made to apply the equalization of the spacings to the images and the masks.\n",
    "class EqualizeSpacing(monai.transforms.Transform):\n",
    "    def __call__(self, sample):\n",
    "        # The original size and spacings of the images and masks are stored in the sample dictionary.\n",
    "        # This is done so the image can be transformed back after inference\n",
    "        sample['org_size'] = sample['img_size']\n",
    "        sample['org_spacing'] = sample['img_spacing']\n",
    "        \n",
    "        # Here all dimensions are equally spaced to 1.25\n",
    "        image = resample_img(sample['img'], [1.25, 1.25, 1.25], False)\n",
    "        sample['img'] = image\n",
    "        sample['img_size'] = image.GetSize()\n",
    "        sample['img_spacing'] = image.GetSpacing()\n",
    "\n",
    "        # Here all dimensions are equally spaced to 1.25 similarly as the images above.\n",
    "        mask = resample_img(sample['mask'], [1.25, 1.25, 1.25], True)\n",
    "        sample['mask'] = mask\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b600de2-a2d8-465f-8a2a-7ce7f35a2fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:58:11.783027400Z",
     "start_time": "2024-06-16T12:58:11.755105200Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A function 'LoadData' is made to convert the SimpleITK objects to NumPy arrays.\n",
    "class LoadData(monai.transforms.Transform):\n",
    "    def __call__(self, sample):\n",
    "        # Converting the SimpleITK objects to NumPy arrays for the images and the masks.\n",
    "        sample['img'] = sitk.GetArrayFromImage(sample['img'])\n",
    "        sample['mask'] = sitk.GetArrayFromImage(sample['mask'])\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6d776-39b6-4675-a8cb-04e2bd8f30a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:58:13.287489100Z",
     "start_time": "2024-06-16T12:58:11.771059700Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'database'\n",
    "# Here the initial training set is computed. \n",
    "train_dict_list = build_dicts(data_path, mode='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f64ed2-b9de-413c-b723-507b3a3c6d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here the validation set is computed where it includes 10% (ratio=0.1) of the patients and the training set is updated, since the validation set gets extracted. \n",
    "train_dict_list, val_dict_list = split_train_val(train_dict_list, ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b87b67-788e-448d-a945-e15ebdcee14c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:58:13.330371Z",
     "start_time": "2024-06-16T12:58:13.281509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data augmentation is applied to increase the regularization of the model. \n",
    "# Two separate composed transformer functions are made for the training set and the dataset using the MONAI library.\n",
    "\n",
    "train_transforms = monai.transforms.Compose([\n",
    "    ReadFiles(),        # Applies the 'ReadFiles' function\n",
    "    EqualizeSpacing(),  # Applies the 'EqualizeSpacing' function\n",
    "    LoadData(),         # Applies the 'LoadData' function  \n",
    "    EnsureChannelFirstd(channel_dim=\"no_channel\", keys=[\"img\", \"mask\"]),\n",
    "    ScaleIntensityd(keys=[\"img\"]), # Normalize the intensity\n",
    "    RandGaussianNoised(keys=['img'], prob=1, mean=0, std=0.075),# Random rotate data between 0.4 and 0.4 radians to represent other orientations of the heart in a realistic range.\n",
    "    RandRotated(keys=[\"img\", \"mask\"], prob=1, range_x=(0.4, 0.4), mode=['bilinear', 'nearest']),  # Add random Gaussian noise\n",
    "    RandSpatialCropd(keys=['img', 'mask'], roi_size=[32, 176, 176], random_size=False).set_random_state(0), # Random crop\n",
    "])\n",
    "\n",
    "val_transforms = monai.transforms.Compose([\n",
    "    ReadFiles(),        # Applies the 'ReadFiles' function\n",
    "    EqualizeSpacing(),  # Applies the 'EqualizeSpacing' function\n",
    "    LoadData(),         # Applies the 'LoadData' function  \n",
    "    EnsureChannelFirstd(channel_dim=\"no_channel\", keys=[\"img\", \"mask\"]),\n",
    "    ScaleIntensityd(keys=[\"img\"]), # Normalize the intensity\n",
    "    RandSpatialCropd(keys=['img', 'mask'], roi_size=[32, 176, 176], random_size=False).set_random_state(0),  # Random crop\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b07591-de0f-454d-bf00-d92eae589a42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:59:44.794236600Z",
     "start_time": "2024-06-16T12:58:13.330371Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applying the composed transform function to the train and validation data sets.\n",
    "train_dataset = monai.data.CacheDataset(data=train_dict_list, transform=train_transforms)\n",
    "val_dataset = monai.data.CacheDataset(data=val_dict_list, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e3172-8ff8-43ee-9aee-879324825144",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Defining training and validation loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d277354-1272-44c1-9630-88ff90b1477b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:59:45.777653700Z",
     "start_time": "2024-06-16T12:59:44.810189600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the training and validation loaders. \n",
    "train_loader = monai.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "val_loader = monai.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39f5ed-ea1b-42c5-84d3-2fd110299ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:59:45.794606300Z",
     "start_time": "2024-06-16T12:59:45.778650900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e458ce-9f63-43f0-85e6-e1c7ab28553c",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7a671-d124-47cb-97cc-0421d3872fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T12:59:46.477869100Z",
     "start_time": "2024-06-16T12:59:45.803581700Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A 3D U-net is created with the MONAI library\n",
    "model = monai.networks.nets.UNet(\n",
    "    spatial_dims=3,                   # Two dimensions (axial 2D slice)\n",
    "    in_channels=1,                    # In channel = scan-file\n",
    "    out_channels=4,                   # Output channel = background, right endocardium, left endocardium and left myocardium\n",
    "    channels=(48, 96, 192, 384, 768), # Defined layers\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    dropout=0.25                      # Drop-out for regularization of the model\n",
    ").to(device)\n",
    "\n",
    "# Defining the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Defining the Dice loss function\n",
    "loss_function = monai.losses.DiceLoss(batch=True, softmax=True, to_onehot_y=True, include_background=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631bcfbc-43ab-4d76-bbc0-6a82fb43f009",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c80f75e-8976-4e91-b171-41bab0499125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:12:18.294321200Z",
     "start_time": "2024-06-16T12:59:46.506789600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choosing amount of epochs\n",
    "epochs = 150\n",
    "\n",
    "# Initiate a training progress on weights and biases.\n",
    "run = wandb.init(\n",
    "    name='Unet_3d'\n",
    ")\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    steps = 0\n",
    "    for train_batch in train_loader:\n",
    "        steps += 1\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_batch['img'].float().to(device))\n",
    "        loss = loss_function(outputs, train_batch['mask'].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= steps\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    steps = 0\n",
    "    for val_batch in val_loader:\n",
    "        steps += 1\n",
    "        with torch.no_grad():\n",
    "            outputs = model(val_batch['img'].float().to(device))\n",
    "            loss = loss_function(outputs, val_batch['mask'].to(device))\n",
    "        val_loss += loss.item()\n",
    "    val_loss /= steps\n",
    "    \n",
    "    wandb.log({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss})\n",
    "\n",
    "run.finish()\n",
    "torch.save(model.state_dict(), r'trainedUNet3D_noise04en0.1std.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
